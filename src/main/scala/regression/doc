最小二乘法：
    残差：预测值与计算值之间的差值
    误差：实际值与计算值之间的差值
    最小二乘法是残差平方和，自变量与因变量已知，对常数求偏导数，求出两个常数值，即为最合适对回归线



随机梯度下降（SGD):
    随机梯度下降是一种机器学习中常用的优化方法，它是通过不断迭代更新的手段，来寻找某一个函数的全局
    最优解的方法。与最小二乘法类似，都是优化算法，随机梯度下降特别适合变量众多，受控系统复杂的模型。


交叉验证法：针对欠拟合，取训练集和测试集同时达到最优时刻的点。

正则化原理：针对过拟合，模型过于复杂，超过实际需要，对模型对复杂程度进行量化，对复杂模型进行"惩罚"，以便
    使模型更加"中庸"。


